---
title: "Breast Cancer Type Prediction using Proteomic Data"
author: "Ngoc Duong - nqd2000"
date: "05/15/2020"
output: github_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(caret)
library(tidyverse)
library(data.table)
library(viridis)
library(mgcv)
library(ggplot2)
library(pdp)
library(patchwork)
library(janitor)
library(ModelMetrics)
library(caret)
library(microbenchmark)
library(RColorBrewer)
library(factoextra)
library(broom)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

# Data cleaning 

**Import data and get rid of NA values**

```{r}
#import data
outcome = read.csv("./breastcancerproteomes/clinical_data_breast_cancer.csv") %>% janitor::clean_names()
proteome = read.csv("./breastcancerproteomes/77_cancer_proteomes_CPTAC_itraq.csv") 

#clean proteome data
#transpose dataset
proteome_tp <- transpose(proteome)

#get row and colnames in order
colnames(proteome_tp) <- proteome$RefSeq_accession_number
proteome_tp$par_id <- colnames(proteome) 

#rearrange data
proteome_with_id = as_tibble(proteome_tp) %>% select(par_id, everything()) %>% .[-c(1:3),] %>% separate(par_id, c("id2","id4","tcga")) %>% select(-tcga)

proteome_wo_id = as_tibble(proteome_tp) %>% select(-par_id, everything()) %>% .[-c(1:3),-ncol(proteome_tp)]
  
#clean outcome data 
outcome_clean = outcome %>% 
  separate(complete_tcga_id, c("tcga","id2","id4"), "-") %>% #sep id based on 2-digit id and 4-digit id
  select(-tcga) %>% 
  select(id2, id4, node_coded)

bcp_merge = left_join(proteome_with_id, outcome_clean, by = c("id2","id4")) %>% select(-id2, -id4) %>% drop_na(node_coded)
```
 
**Leave out proteins that have missing quantification values**

```{r}
missing.counts <- NULL
for(i in 1:ncol(proteome_wo_id)) {
missing.counts[i] <- sum(is.na(proteome_wo_id[,i]))}

miss <- names(proteome_wo_id)[which(missing.counts >= 1)] 

proteome_woid_nona = proteome_wo_id[-c(81:83),!(colnames(proteome_wo_id) %in% c(miss))]
```

**Screening variables**

```{r}
#find variance for all proteins
var <- NULL
for(i in 1:ncol(proteome_woid_nona)){
var[i] <- var(proteome_woid_nona[,i])}

var_id = tibble(row = c(1:7994), var) %>% arrange(desc(var)) %>% slice(1:5000)

#find names of proteins with high variances and put them in a vector
sup.var = names(proteome_woid_nona)[var_id$row]

#subset original data with the created vector
proteome_final = proteome_woid_nona[,c(sup.var)] %>% mutate_all(as.numeric) %>% as.matrix()

#use t-test to find proteins that are most associatd with the outcome
t_test = NULL
for(i in 1:ncol(proteome_final)){
  t_test[i] = t.test(proteome_final[,i]~bcp_merge$node_coded)$p.value
}

t_test_id = tibble(row = c(1:5000), t_test) %>% arrange(t_test) %>% slice(1:500)

low.pval = names(as_tibble(proteome_final))[t_test_id$row]

proteome_final2 = as_tibble(proteome_final) 
proteome_final3 = proteome_final2[,c(low.pval)] %>% mutate_all(as.numeric) 
```


**Obtain final data**

```{r}
#merge proteome and clinical data 
bcp_data = cbind(proteome_final3, node = bcp_merge$node_coded) %>% as_tibble() %>% drop_na(node) %>% mutate_at(vars(-node), as.numeric) 
```

# Exploratory data analysis

## Some unsupervised learning

**k-means**
Use function fviz_nbclust to determine the optimal number of clusters using average sillhouette.

```{r}
bcp_eda = bcp_data %>% select(-node)
bcp_eda1 = scale(bcp_eda)
fviz_nbclust(bcp_eda1, 
             FUNcluster = kmeans,
             method = "silhouette")
```


```{r}
#make clusters
set.seed(13)

km = kmeans(bcp_eda1, centers = 7, nstart = 30)

fviz_cluster(list(data = bcp_eda1, cluster = km$cluster),
                      ellipse.type = "convex",
                      geom = c("point","text"),
                      labelsize = 5,
                      palette  = "Dark2") + 
  labs(title = "Clusters based on k-means results") + theme_bw()
```


```{r}
ind4.complete <-cutree(hc.complete, 4)

# Who are in the fourth cluster?
bcp_eda1[ind4.complete==4,]
```

To display more details, we show the heatmap of the data.
```{r}
library(corrplot)
library(gplots)
#display.brewer.all(n=NULL, type="all", select=NULL, exact.n=TRUE)
col1 <-colorRampPalette(brewer.pal(9, "GnBu"))(100)
col2 <-colorRampPalette(brewer.pal(3, "Spectral"))(2)

heatmap.2(bcp_eda1,col = col1, 
          keysize=.8, key.par =list(cex=.5),
          trace = "none", key = TRUE, 
          #cexCol = 0.75, labCol =as.character(bcp_eda1[,1]),
          #ColSideColors = col2[as.numeric(dat[,"Legendary"])+1],
          margins =c(10, 10))
```

**Grouped boxplots**

```{r}
#top 20 genes with highest variance
bcp_data %>% dplyr::select(c(1:20, 501)) %>% 
  pivot_longer(1:20,
               names_to = "protein",
               values_to = "value") %>% 
  group_by(node) %>% 
  ggplot(aes(x = protein, y = value, color = node)) +
  geom_boxplot() + theme_bw() + 
  labs(y = "Expression levels", x = "Protein") + facet_grid(~node) + 
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 40, hjust = 1))

#mid 30 proteins with highest variance
bcp_data %>% dplyr::select(c(241:270, 501)) %>% 
  pivot_longer(1:30,
               names_to = "protein",
               values_to = "value") %>% 
  group_by(node) %>% 
  ggplot(aes(x = protein, y = value, color = node)) +
  geom_boxplot() + theme_bw() + 
  labs(y = "Expression levels", x = "Protein") + 
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 40, hjust = 1))

#40 proteins with lowest variance
bcp_data %>% dplyr::select(c(461:500, 501)) %>% 
  pivot_longer(1:40,
               names_to = "protein",
               values_to = "value") %>% 
  group_by(node) %>% 
  ggplot(aes(x = protein, y = value, color = node)) +
  geom_boxplot() + theme_bw() + 
  labs(y = "Expression levels", x = "Protein") + 
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 40, hjust = 1))
```


# Prediction

```{r}
#create training set with a random sample of 800 observations
set.seed(13)
rowTrain <-createDataPartition(y = bcp_data$node,
                               p = 0.80,
                               list = FALSE)
bcp_train = bcp_data[rowTrain,]
bcp_test = bcp_data[-rowTrain,]
```


### Random Forest

```{r}
ctrl_cl = trainControl(method = "repeatedcv",
                    summaryFunction = twoClassSummary,
                    classProbs = TRUE)

rf.grid = expand.grid(mtry = 2:30, 
                      splitrule = "gini",
                      min.node.size = 1:6)

set.seed(13)
rf.fit <- train(node~., bcp_train,
                method = "ranger",
                tuneGrid = rf.grid,
                metric = "ROC",
                importance = "permutation", 
                trControl = ctrl_cl)

ggplot(rf.fit, highlight = TRUE)
```

Variable importance

```{r}
varimp = varImp(rf.fit)$importance

varimp$protein = rownames(varimp) 
varimp = as_tibble(varimp) %>% arrange(desc(Overall)) %>% slice(1:80)
```

**Hierarchical clustering**

Prepare data for hierarchical clustering 

```{r}
bcp_hclust = bcp_eda1[,c(varimp$protein)]

#specify clustering types
hc.complete <-hclust(dist(bcp_hclust), method = "complete")
hc.average <-hclust(dist(bcp_hclust), method = "average")
hc.single <-hclust(dist(bcp_hclust), method = "single")
```


```{r}
hc.complete$labels = as.vector(varimp$protein)
fviz_dend(hc.complete, 
          k = 4, cex = 0.5, palette = "jco",
          color_labels_by_k = TRUE,
          rect = TRUE, rect_fill = TRUE, 
          rect_border = "jco",
          labels_track_height = 2.5, horiz = TRUE)
```

Random Forest prediction results 

**Train error rate**

```{r}
rf.pred.train = predict(rf.fit, bcp_train, type = "prob")
rf.pred.res.train = ifelse(rf.pred.train$Negative > 0.5,'Negative','Positive')
table(rf.pred.res.train, bcp_train$node)
```

Error rate = (`r table(rf.pred.res.train, bcp_train$node)[2]` + `r table(rf.pred.res.train, bcp_train$node)[3]`)/68 = `r (table(rf.pred.res.train, bcp_train$node)[2] + table(rf.pred.res.train, bcp_train$node)[3])/68`

**Test error rate**

```{r}
rf.pred.test = predict(rf.fit, bcp_test, type = "prob")
rf.pred.res.test = ifelse(rf.pred.test$Negative > 0.5,'Negative','Positive')
table(rf.pred.res.test, bcp_test$node)
```

Error rate = (`r table(rf.pred.res.test, bcp_test$node)[2]` + `r table(rf.pred.res.test, bcp_test$node)[3]`)/12 = `r (table(rf.pred.res.test, bcp_test$node)[2] + table(rf.pred.res.test, bcp_test$node)[3])/12`

## Support vector classifier/machine

### Fit a support vector classifier (linear kernel) to the training data with Tumor Type as the response

```{r}
ctrl <-trainControl(method = "repeatedcv")

set.seed(13)
svml.fit <-train(node~.,data = bcp_train,
                 method = "svmLinear2",
                 allowParallel = TRUE,
                 preProc = c("scale", "center"),
                 tuneGrid =data.frame(cost =exp(seq(-13,-1,len=20))),
                 trControl = ctrl)

ggplot(svml.fit, highlight = TRUE)
```

**Find the training and test error rate**

Training error rate

```{r}
pred.svml.train <-predict(svml.fit, newdata = bcp_train)
caret::confusionMatrix(data = pred.svml.train, reference = bcp_train$node)
```

Test error rate 

```{r}
pred.svml.test <-predict(svml.fit, newdata = bcp_test)
caret::confusionMatrix(data = pred.svml.test, reference = bcp_test$node)
```

### Fit a support vector machine (radial kernel) to the training data with Tumor Type as the response

```{r}
svmr.grid <-expand.grid(C =exp(seq(-9,3,len=25)),
                        sigma =exp(seq(-10,1,len=15)))

set.seed(13)
svmr.fit <-train(node~.,data = bcp_train,
                 method = "svmRadial",
                 allowParallel=TRUE,
                 tuneGrid = svmr.grid,
                 trControl = ctrl)

ggplot(svmr.fit, highlight = TRUE)
```

**Find the training and test error rate**

Training error rate

```{r}
pred.svmr.train <-predict(svmr.fit, newdata = bcp_train)
caret::confusionMatrix(data = pred.svmr.train, reference = bcp_train$node)
```

Test error rate

```{r}
pred.svmr.test <-predict(svmr.fit, newdata = bcp_test)
caret::confusionMatrix(data = pred.svmr.test, reference = bcp_test$node)
```