---
title: "stl2137_trees"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(tidyverse)
library(randomForest)
library(gbm)
library(rpart)
library(rpart.plot)
library(pROC)
library(ranger)
library(gbm)
```


```{r}
load("./final_data.RData")

set.seed(13)
rowTrain <-createDataPartition(y = bcp_data$node,
                               p = 0.80,
                               list = FALSE)
bcp_train = bcp_data[rowTrain,]
bcp_test = bcp_data[-rowTrain,]
```

## Classification Trees

```{r}
set.seed(13)
tree1 <- rpart(formula = node ~., data = bcp_train,
               control = rpart.control(cp = 0))

cpTable <- printcp(tree1)
plotcp(tree1)
minErr <- which.min(cpTable[,4])

tree2 <- prune(tree1, cp = cpTable[minErr,1])
rpart.plot(tree2)
```

## Random Forest

```{r}
control <- trainControl(method = "repeatedcv",
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)
```

### Using Square Root Range
```{r}
rf_grid <- expand.grid(mtry = 1:22,
                       splitrule = "gini",
                       min.node.size = 1:5)

set.seed(13)
rf_fit <- train(node ~., bcp_train,
                method = "ranger",
                tuneGrid = rf_grid,
                metric = "ROC",
                trControl = control)

ggplot(rf_fit, highlight = TRUE)
```

## Random Forest Test Prediction & Error 

```{r}
### Train
rf_train_pred <- predict(rf_fit, newdata = bcp_train, type = "prob")
rf_pred_train_error <- ifelse(rf_train_pred$Negative > 0.5, "Negative", "Positive")
table(rf_pred_train_error, bcp_train$node)

### Test 
rf_pred <- predict(rf_fit, newdata = bcp_test, type = "prob")
rf_pred_test_error <- ifelse(rf_pred$Negative > 0.5, "Negative", "Positive")
table(rf_pred_test_error, bcp_test$node)
```


```{r}
### 1:30 Range
rf_pred <- predict(rf_fit, newdata = bcp_test, type = "prob")
rf_pred_test_error <- ifelse(rf_pred$Negative > 0.5, "Negative", "Positive")
table(rf_pred_test_error, bcp_test$node)

### Square Root 
rf_pred_sqrt <- predict(rf_fit_sqrt, newdata = bcp_test, type = "prob")
rf_pred_sqrt_test_error <- ifelse(rf_pred_sqrt$Negative > 0.5, "Negative", "Positive")
table(rf_pred_sqrt_test_error, bcp_test$node)
```

## Boosting 

### Distribution = Bernoulli 
```{r}
bern_boosting_grid <- expand.grid(n.trees = c(1000, 2000,3000),
                        interaction.depth = 1:4,
                        shrinkage = c(0.001, 0.003, 0.005, 0.01),
                        n.minobsinnode = 1)

set.seed(13)
# Binomial loss function
bern_boosting_fit <- train(node~., bcp_train, 
                 tuneGrid = bern_boosting_grid,
                 trControl = control,
                 method = "gbm",
                 distribution = "bernoulli",
                 metric = "ROC",
                 verbose = FALSE)

ggplot(bern_boosting_fit, highlight = TRUE)

bern_boosting_pred <- predict(bern_boosting_fit, newdata = bcp_test, type = "prob")
bern_boosting_test_error <- ifelse(bern_boosting_pred$Negative > 0.5, "Negative", "Positive")
table(bern_boosting_test_error, bcp_test$node)
```

### AdaBoosting
```{r}
adaboosting_grid <- expand.grid(n.trees = c(1000, 2000,3000),
                        interaction.depth = 1:4,
                        shrinkage = c(0.001, 0.003, 0.005, 0.01),
                        n.minobsinnode = 1)
set.seed(13)
# Adaboost loss function
adaboosting_fit <- train(node ~., bcp_train, 
                 tuneGrid = adaboosting_grid,
                 trControl = control,
                 method = "gbm",
                 distribution = "adaboost",
                 metric = "ROC",
                 verbose = FALSE)

ggplot(adaboosting_fit, highlight = TRUE)

adaboosting_pred <- predict(adaboosting_fit, newdata = bcp_test, type = "prob")
adaboosting_test_error <- ifelse(adaboosting_pred$Negative > 0.5, "Negative", "Positive")
table(adaboosting_test_error, bcp_test$node)
```

# Resampling

```{r}
resamp <- resamples(list(random_forest = rf_fit,
                         random_forest_sqrt = rf_fit_sqrt,
                         bernoulli_boosting = bern_boosting_fit,
                         adaboosting = adaboosting_fit))

summary(resamp)
```


# Test Data Performance

```{r}
roc_rf <- roc(bcp_test$node, rf_pred[,1])
roc_rf_sqrt <- roc(bcp_test$node, rf_pred_sqrt[,1])
roc_bern_boost <- roc(bcp_test$node, bern_boosting_pred[,1])
roc_adaboost <- roc(bcp_test$node, adaboosting_pred[,1])
  
plot(roc_rf)
plot(roc_rf_sqrt, add = TRUE, col = 2)
plot(roc_bern_boost, add = TRUE, col = 3)
plot(roc_adaboost, add = TRUE, col = 4)

auc <- c(roc_rf$auc[1], roc_rf_sqrt$auc[1], roc_bern_boost$auc[1], roc_adaboost$auc[1])


modelNames <- c("random forest","random forest sqrt","bernoulli boost","adaboost")
legend("bottomright", legend = paste0(modelNames, ": ", round(auc,3)),
       col = 1:6, lwd = 2)
```

